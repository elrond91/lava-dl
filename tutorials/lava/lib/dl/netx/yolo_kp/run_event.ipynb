{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc75815f-8370-4355-bd5a-67969bd03c4f",
   "metadata": {},
   "source": [
    "# YOLO-KP SDNN Example\n",
    "\n",
    "This tutorial demonstrates the inference of YOLO-KP SDNN (training example scripts [here](https://github.com/lava-nc/lava-dl/tree/main/tutorials/lava/lib/dl/slayer/tiny_yolo_sdnn)) on both CPU and Loihi 2 neurocore.\n",
    "\n",
    "![image](https://github.com/lava-nc/lava/assets/29907126/61057e64-71b3-4ab8-a7ea-39d0cdbac70d)\n",
    "\n",
    "YOLO-KP is a fully convolutional single-headed variant of TinyYOLOv3 object detection architecture specifically designed for 8 chip Loihi 2 form factor called Kapoho Point (KP). The inference example uses the following lava components\n",
    "\n",
    "1. __Network on Loihi 2:__ YOLO-KP network generated from its NetX description. It is a hierarchical network consisting of all the layers of YOLO-KP. This is the portion that runs on Loihi.\n",
    "2. __Data sparsification on SuperHost:__ Delta encoder process that performs frame difference to sparsify the input being communicated to the YOLO-KP network. This process runs on Python.\n",
    "3. __Data communication in and out of lava processes:__ `Injector` process to send raw input to the lava network and `Extractor` process to receive raw output of YOLO-KP. These processes run on Python.\n",
    "4. __Data relay in and out of Loihi chip:__ Input and output adapter process which relay the communication into the chip and out of the chip. Since YOLO-KP is fully convolutional, the adapters translate to/from python spike and Loihi convolution spike.\n",
    "\n",
    "> ℹ️ This example currently does not make use of high speed IO capabilities of Loihi and hence the execution is slow. Once the software support is enabled in Lava, these adapters will not be required and shall be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56595d79-183f-4b78-a000-e8fbefcfd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg, Loihi2SimCfg\n",
    "from lava.proc import embedded_io as eio\n",
    "from lava.proc import io\n",
    "\n",
    "from lava.lib.dl import netx\n",
    "from lava.lib.dl import slayer\n",
    "from lava.lib.dl.slayer import obd\n",
    "\n",
    "from utils import DataGenerator, YOLOPredictor, nms, YOLOMonitor\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb22d4-d01b-4219-a106-d7ce40c750b3",
   "metadata": {},
   "source": [
    "# Import modules for Loihi2 execution\n",
    "\n",
    "Check if Loihi2 compiler is available and import related modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08beb08c-b9a2-44e1-ad63-d2fa9f2cfc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on loihi\n"
     ]
    }
   ],
   "source": [
    "from lava.utils.system import Loihi2\n",
    "Loihi2.preferred_partition = 'loihi'\n",
    "loihi2_is_available = Loihi2.is_loihi2_available\n",
    "\n",
    "#loihi2_is_available = False\n",
    "\n",
    "if loihi2_is_available:\n",
    "    print(f'Running on {Loihi2.partition}')\n",
    "    from lava.magma.compiler.subcompilers.nc.ncproc_compiler import CompilerOptions\n",
    "    CompilerOptions.verbose = True\n",
    "    compression = io.encoder.Compression.DELTA_SPARSE_8\n",
    "else:\n",
    "    print(\"Loihi2 compiler is not available in this system. \"\n",
    "          \"This tutorial will execute on CPU backend.\")\n",
    "    compression = io.encoder.Compression.DENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b3f8a-3405-496a-bae8-c5e3c4bac788",
   "metadata": {},
   "source": [
    "## Set execution parameters\n",
    "\n",
    "The network execution parameters can be divided into three categories:\n",
    "\n",
    "1. __Model parameters:__ these are parameters of the YOLO model used for the training and shall be reused to replicate the same behavior during inference.\n",
    "2. __Inference parametrs:__ these are parameters just for the inference.\n",
    "3. __Data processing parameters:__ these are parameters need to perform _pre_ and _post_ processing before the input and on the output of the network respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdb59a7-04ae-4a5f-89a1-7b3fcb81750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model arguments\n",
    "trained_folder = os.path.abspath('../../slayer/tiny_yolo_sdnn/Trained_yolo_kp_events')\n",
    "with open(trained_folder + '/args.txt', 'rt') as f:\n",
    "    model_args = slayer.utils.dotdict(yaml.safe_load(f))\n",
    "\n",
    "# Additional inference arguments\n",
    "inference_args = slayer.utils.dotdict(loihi=loihi2_is_available,\n",
    "                                      spike_exp=4,    # This sets the decimal/fraction precision of spike message to 4 bits\n",
    "                                      num_steps=5)  # Number of frames to perform inference on\n",
    "\n",
    "# Pre and post processing parameters\n",
    "#pre_args = slayer.utils.dotdict(input_mean=np.array([0.485, 0.456, 0.406]),  # Input normalization mean\n",
    "#                                input_std=np.array([0.229, 0.224, 0.225]))   #                     & std\n",
    "post_args = slayer.utils.dotdict(anchors=np.array([(0.28, 0.22),  # YOLO head's anchor preset scales\n",
    "                                                   (0.38, 0.48),\n",
    "                                                   (0.90, 0.78)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9ad4b-6c01-4f85-9413-8761aa725f07",
   "metadata": {},
   "source": [
    "## Load YOLO-KP network\n",
    "\n",
    "Loading the network is a simple NetX call on the trained model computational graph. It will generate an hierarchical lava process representing the entire YOLO-KP network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21049ee5-398d-4c7a-8431-0f6322e747de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was trained for PropheseeAutomotive dataset\n",
      "\n",
      "Network Architecture (yolo_kp_events):\n",
      "======================================\n",
      "|   Type   |  W  |  H  |  C  | ker | str | pad | dil | grp |delay|\n",
      "|Conv      |  224|  224|   16| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |  112|  112|   32| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   56|   56|   64| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   28|   28|  128| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   28|   28|  256| 3, 3| 1, 1| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  256| 3, 3| 2, 2| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  512| 3, 3| 1, 1| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  256| 1, 1| 1, 1| 0, 0| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|  512| 3, 3| 1, 1| 1, 1| 1, 1|    1|False|\n",
      "|Conv      |   14|   14|   36| 1, 1| 1, 1| 0, 0| 1, 1|    1|False|\n"
     ]
    }
   ],
   "source": [
    "net = netx.hdf5.Network(trained_folder + '/network.net',\n",
    "                        input_shape = (448, 448, 2),\n",
    "                        #skip_layers = 1,  # First layer does delta encoding. We will only send it's sparsified output\n",
    "                        input_message_bits=16,  # This means the network takes 16bit graded spike input\n",
    "                        spike_exp=inference_args.spike_exp)\n",
    "print(f'The model was trained for {model_args.dataset} dataset')\n",
    "print(f'\\nNetwork Architecture ({model_args.model}):'); print('=' * (24 + len(model_args.model))); print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afeb7d-53ba-472f-9ef4-967d8043da14",
   "metadata": {},
   "source": [
    "## Dataset and input source\n",
    "\n",
    "The dataset is the same module that is used for training. It is wrapped around by a data generator module that will generate an individual frame and its annotation at every time-step. The data generator also takes care of data normalization using the mean and variance supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eaacf43-0ce3-4e95-b331-59c6f609acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = obd.dataset.PropheseeAutomotive(root=model_args.path,\n",
    "                           train=False, randomize_seq=False,\n",
    "                           seq_len=inference_args.num_steps)\n",
    "data_gen = DataGenerator(dataset=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeace54f",
   "metadata": {},
   "source": [
    "## Input preprocessing and encoding\n",
    "\n",
    "The input preprocessing involves quantization of the numeric data making it ready to be processed on the chip. A fractional representation of 6 bits was used in the weight of the network during training (`weight_exp`) which is also accounted for during quantization.\n",
    "\n",
    "The quantized input frames are then processed the the lava processes `sender`, `encoder` (and `inp_adapter` for Loihi execution) which will be connected in a sequential manner below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize = netx.modules.Quantize(exp=6)  # convert to fixed point representation with 6 bit of fraction\n",
    "sender = io.injector.Injector(shape=net.inp.shape, buffer_size=128)\n",
    "#encoder = io.encoder.DeltaEncoder(shape=net.inp.shape,\n",
    "#                                  vth=net.net_config['layer'][0]['neuron']['vThMant'],\n",
    "#                                  spike_exp=0 if inference_args.loihi else net.spike_exp,\n",
    "#                                  num_bits=8,\n",
    "#                                  compression=compression)\n",
    "\n",
    "if inference_args.loihi:\n",
    "    # This is needed for the time being until high speed IO is enabled\n",
    "    inp_adapter = eio.spike.PyToN3ConvAdapter(shape=(448, 448, 2),\n",
    "                                              num_message_bits=16,\n",
    "                                              spike_exp=net.spike_exp,\n",
    "                                              compression=compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc614a5",
   "metadata": {},
   "source": [
    "## Output decoding and post processing\n",
    "\n",
    "The output of YOLO-KP goes through (`state_adapter` for Loihi execution), `receiver` and `dequantizer` lava processes which will be connected sequentially. The raw outputs needs to be processed using `yolo_predictor` which transforms the input to the actual bounding box predictions of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449d0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_args.loihi:\n",
    "    # This is needed for the time being until high speed IO is enabled\n",
    "    state_adapter = eio.state.ReadConv(shape=net.out.shape)\n",
    "receiver = io.extractor.Extractor(shape=net.out.shape, buffer_size=128)\n",
    "dequantize = netx.modules.Dequantize(exp=net.spike_exp + 12, num_raw_bits=24)\n",
    "yolo_predictor = YOLOPredictor(anchors=post_args.anchors, clamp_max=model_args.clamp_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3164b-8d41-402f-adac-e39264f88e47",
   "metadata": {},
   "source": [
    "## Output visualization\n",
    "\n",
    "`YOLOMonitor` is a flexible output visualization and evaluation module. It continuously evaluates the mAP score of the output predictions. It can also be passed a callable function that can be used to display. In this case it is a basic iPython display routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571c9df9-971f-4eb3-aa45-633081fd9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_visualizer(annotated_frame, map_score, frame_idx):\n",
    "    clear_output(wait=True)\n",
    "    display(annotated_frame)\n",
    "    print(f'Processed frame {frame_idx}')\n",
    "    print(f'Object detection mAP@0.5 = {map_score:.2f}')\n",
    "    \n",
    "yolo_monitor = YOLOMonitor(viz_fx=output_visualizer, class_list=test_set.classes, events=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba7ca7",
   "metadata": {},
   "source": [
    "## Data buffers / delays\n",
    "\n",
    "There is a latency in the prediction equal to the number of layers the network has and the encoding step. Two FIFO buffers are used to synchronize the input frame and target annotation with the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9242a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_buffer = netx.modules.FIFO(depth=len(net) + 1)\n",
    "annotation_buffer = netx.modules.FIFO(depth=len(net) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3b7d2",
   "metadata": {},
   "source": [
    "# Connect Lava processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2571441-fd3c-447c-8e5d-703e23d313d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_args.loihi:\n",
    "    sender.out_port.connect(inp_adapter.inp)\n",
    "    #encoder.s_out.connect(inp_adapter.inp)\n",
    "    inp_adapter.out.connect(net.inp)\n",
    "    state_adapter.connect_var(net.out_layer.neuron.sigma)\n",
    "    state_adapter.out.connect(receiver.in_port)\n",
    "else:\n",
    "    sender.out_port.connect(net.inp)\n",
    "    #encoder.s_out.connect(net.inp)\n",
    "    net.out.connect(receiver.in_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67623b71",
   "metadata": {},
   "source": [
    "# Setup execution\n",
    "\n",
    "The network is run in _non-blocking mode_. Note the `blocking=False` argument below. In non-blocking mode we can start running the lava process and do other computations in parallel. Here we will preprocess the data, send it to lava network using `sender` (`lava.proc.io.injector.Injector` instance), receive data from lava using `receiver` (`lava.proc.io.extractor.Extractor` instance), and perform additional processing, while the Lava network is running in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7baa7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = inference_args.num_steps\n",
    "run_condition = RunSteps(num_steps=num_steps, blocking=False)\n",
    "\n",
    "if inference_args.loihi:\n",
    "    exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelSparse}\n",
    "    run_config = Loihi2HwCfg(exception_proc_model_map=exception_proc_model_map)\n",
    "else:\n",
    "    exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelDense}\n",
    "    run_config = Loihi2SimCfg(select_tag='fixed_pt',\n",
    "                              exception_proc_model_map=exception_proc_model_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33bdc8",
   "metadata": {},
   "source": [
    "# Run YOLO-KP inference\n",
    "\n",
    "The following will compile and run the Lava network.\n",
    "\n",
    "> ℹ️ The network is large. It will take a while for the compilation to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c557db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing partitiorns!\n",
      "done partitiorns!\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sender\u001b[38;5;241m.\u001b[39m_log_config\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARN\n\u001b[0;32m----> 2\u001b[0m \u001b[43msender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lava-nc/lava-sumit/lava/src/lava/magma/core/process/process.py:364\u001b[0m, in \u001b[0;36mAbstractProcess.run\u001b[0;34m(self, condition, run_cfg, compile_config)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_cfg:\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_cfg must not be None when calling\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    362\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Process.run() unless the process has already\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m been compiled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_runtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runtime\u001b[38;5;241m.\u001b[39mstart(condition)\n",
      "File \u001b[0;32m~/lava-nc/lava-sumit/lava/src/lava/magma/core/process/process.py:388\u001b[0m, in \u001b[0;36mAbstractProcess.create_runtime\u001b[0;34m(self, run_cfg, executable, compile_config)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a runtime for this process and all connected processes by\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03mcompiling the process to an executable and assigning that executable to\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mthe process and connected processes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Configuration options for the Compiler and SubCompilers.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 388\u001b[0m     executable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runtime \u001b[38;5;241m=\u001b[39m Runtime(executable,\n\u001b[1;32m    390\u001b[0m                         ActorType\u001b[38;5;241m.\u001b[39mMultiProcessing,\n\u001b[1;32m    391\u001b[0m                         loglevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_config\u001b[38;5;241m.\u001b[39mlevel)\n\u001b[1;32m    392\u001b[0m executable\u001b[38;5;241m.\u001b[39massign_runtime_to_all_processes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runtime)\n",
      "File \u001b[0;32m~/lava-nc/lava-sumit/lava/src/lava/magma/core/process/process.py:412\u001b[0m, in \u001b[0;36mAbstractProcess.compile\u001b[0;34m(self, run_cfg, compile_config)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlava\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmagma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compiler\n\u001b[1;32m    411\u001b[0m compiler \u001b[38;5;241m=\u001b[39m Compiler(compile_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_config\u001b[38;5;241m.\u001b[39mlevel)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_cfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lava-nc/lava-sumit/lava/src/lava/magma/compiler/compiler.py:140\u001b[0m, in \u001b[0;36mCompiler.compile\u001b[0;34m(self, process, run_cfg)\u001b[0m\n\u001b[1;32m    138\u001b[0m process_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(proc_groups))\n\u001b[1;32m    139\u001b[0m channel_map \u001b[38;5;241m=\u001b[39m ChannelMap\u001b[38;5;241m.\u001b[39mfrom_proc_groups(proc_groups)\n\u001b[0;32m--> 140\u001b[0m proc_builders, channel_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_proc_groups\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproc_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_map\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m _, c_builders, nc_builders \u001b[38;5;241m=\u001b[39m split_proc_builders_by_type(\n\u001b[1;32m    144\u001b[0m     proc_builders\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    147\u001b[0m node_configs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_node_cfgs(proc_groups)\n",
      "File \u001b[0;32m~/lava-nc/lava-sumit/lava/src/lava/magma/compiler/compiler.py:241\u001b[0m, in \u001b[0;36mCompiler._compile_proc_groups\u001b[0;34m(self, proc_groups, channel_map)\u001b[0m\n\u001b[1;32m    238\u001b[0m     subcompilers\u001b[38;5;241m.\u001b[39mappend(pg_subcompilers)\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# Compile this ProcGroup.\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_proc_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpg_subcompilers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Flatten the list of all SubCompilers.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m subcompilers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(subcompilers))\n",
      "File \u001b[0;32m~/lava-nc/lava-sumit/lava/src/lava/magma/compiler/compiler.py:384\u001b[0m, in \u001b[0;36mCompiler._compile_proc_group\u001b[0;34m(subcompilers, channel_map)\u001b[0m\n\u001b[1;32m    380\u001b[0m channel_map_prev \u001b[38;5;241m=\u001b[39m channel_map\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subcompiler \u001b[38;5;129;01min\u001b[39;00m subcompilers:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# Compile the Processes registered with each SubCompiler and\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# update the ChannelMap.\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     channel_map \u001b[38;5;241m=\u001b[39m \u001b[43msubcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/ncproc_compiler.py:421\u001b[0m, in \u001b[0;36mNcProcCompiler.compile\u001b[0;34m(self, channel_map)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitioner \u001b[38;5;241m=\u001b[39m Partitioner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reg_nets,\n\u001b[1;32m    414\u001b[0m                                 strategies,\n\u001b[1;32m    415\u001b[0m                                 channel_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    418\u001b[0m                                 NcProcCompiler\u001b[38;5;241m.\u001b[39mregnet_strategy_map,\n\u001b[1;32m    419\u001b[0m                                 NcProcCompiler\u001b[38;5;241m.\u001b[39mregnet_partition_map)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone partitiorns!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partitioner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone partitiorns 222!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_channel_map(channel_map)\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/ncproc_compiler.py:1414\u001b[0m, in \u001b[0;36mPartitioner.partition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_core_offset \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_partitions()\n\u001b[0;32m-> 1414\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_partitioning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28mprint\u001b[39m(iteration)\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/ncproc_compiler.py:1469\u001b[0m, in \u001b[0;36mPartitioner._update_partitioning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     reg_net\u001b[38;5;241m.\u001b[39madd_reg_views_for_cx_to_partition(core_ids, partition)\n\u001b[1;32m   1464\u001b[0m     reg_net\u001b[38;5;241m.\u001b[39madd_remaining_reg_views_to_partition(\n\u001b[1;32m   1465\u001b[0m         core_ids,\n\u001b[1;32m   1466\u001b[0m         partition,\n\u001b[1;32m   1467\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregated_port_map)\n\u001b[0;32m-> 1469\u001b[0m \u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_net\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1470\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/optimization/strategy.py:468\u001b[0m, in \u001b[0;36mConvConnStrategy.update_cost\u001b[0;34m(self, partition, regnet)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m core_id \u001b[38;5;129;01min\u001b[39;00m core_ids:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_register_allocation(core_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAxonMap\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    466\u001b[0m                                     tile\u001b[38;5;241m.\u001b[39mnum_axon_map)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_register_allocation(core_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAxonMem\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m--> 468\u001b[0m                                     \u001b[43mtile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_axon_mem\u001b[49m)\n\u001b[1;32m    469\u001b[0m resources \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tile\u001b[38;5;241m.\u001b[39mnum_axon_map \u001b[38;5;241m+\u001b[39m tile\u001b[38;5;241m.\u001b[39mnum_axon_mem\n\u001b[1;32m    470\u001b[0m large_mpds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tile\u001b[38;5;241m.\u001b[39mnum_axon_map \u001b[38;5;241m+\u001b[39m tile\u001b[38;5;241m.\u001b[39mnum_axon_mem\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/neurocore/n3/conv_manager.py:236\u001b[0m, in \u001b[0;36mConvTile.__getattribute__\u001b[0;34m(self, _ConvTile__name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(__name)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# default behavior\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConvTile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m__name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/neurocore/n3/conv_manager.py:464\u001b[0m, in \u001b[0;36mConvTile.num_axon_mem\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m num_dst_cores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_layer\u001b[38;5;241m.\u001b[39mdst_layer:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m region \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdst_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_regions\u001b[49m:\n\u001b[1;32m    465\u001b[0m         x_min, x_max, y_min, y_max \u001b[38;5;241m=\u001b[39m region\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    467\u001b[0m             (x_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_max \u001b[38;5;129;01mand\u001b[39;00m y_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_max)\n\u001b[1;32m    468\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_min \u001b[38;5;241m<\u001b[39m x_max \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_min \u001b[38;5;241m<\u001b[39m y_max)\n\u001b[1;32m    469\u001b[0m         ):\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/neurocore/n3/conv_manager.py:1321\u001b[0m, in \u001b[0;36mConvLayer.input_regions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m regions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtiles:\n\u001b[0;32m-> 1321\u001b[0m     regions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_xy_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m regions\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/neurocore/n3/conv_manager.py:525\u001b[0m, in \u001b[0;36mConvTile.src_xy_range\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m y_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_min \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride_y \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_y, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    521\u001b[0m x_max \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_max \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride_x \\\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation_x \\\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    524\u001b[0m y_max \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_max \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride_y \\\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_y\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation_y \\\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    528\u001b[0m x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(x_max, src_shape_x)\n\u001b[1;32m    529\u001b[0m y_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(y_max, src_shape_y)\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/neurocore/n3/conv_manager.py:233\u001b[0m, in \u001b[0;36mConvTile.__getattribute__\u001b[0;34m(self, _ConvTile__name)\u001b[0m\n\u001b[1;32m    225\u001b[0m parent_attr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_f_in\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_f_out\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    226\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_y\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    227\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstride_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstride_y\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_split\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_split\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_split\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    231\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlsb_atom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsb_atom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __name \u001b[38;5;129;01min\u001b[39;00m parent_attr:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_layer\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(__name)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# default behavior\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(ConvTile, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(__name)\n",
      "File \u001b[0;32m~/lava-nc/frameworks.ai.lava.lava-loihi/src/lava/magma/compiler/subcompilers/nc/neurocore/n3/conv_manager.py:236\u001b[0m, in \u001b[0;36mConvTile.__getattribute__\u001b[0;34m(self, _ConvTile__name)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(__name)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# default behavior\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mConvTile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m(__name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sender._log_config.level = logging.WARN\n",
    "sender.run(condition=run_condition, run_cfg=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2fbc3-c069-40be-9124-2e4db5d06f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(num_steps):\n",
    "    frame, annotation, raw_frame = data_gen()\n",
    "    #frame = quantize(frame)\n",
    "    \n",
    "    sender.send(frame)        # This sends the input frame to the Lava network\n",
    "    out = receiver.receive()  # This receives the output from the Lava network\n",
    "    \n",
    "    out = dequantize(out)\n",
    "    input_frame = frame_buffer(raw_frame)\n",
    "    gt_ann = annotation_buffer(annotation)\n",
    "    if input_frame is not None:  # valid output from FIFO buffer\n",
    "        predictions = yolo_predictor(out)\n",
    "        pred_bbox = nms(predictions)\n",
    "        gt_bbox = obd.bbox.utils.tensor_from_annotation(gt_ann).cpu().data.numpy()\n",
    "        yolo_monitor(input_frame, gt_bbox, pred_bbox)\n",
    "    else:\n",
    "        print(f'Frame {t} queued in pipeline.', end='\\r')\n",
    "\n",
    "sender.wait()\n",
    "sender.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
