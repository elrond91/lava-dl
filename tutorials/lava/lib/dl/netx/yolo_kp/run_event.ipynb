{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc75815f-8370-4355-bd5a-67969bd03c4f",
   "metadata": {},
   "source": [
    "# YOLO-KP SDNN Example\n",
    "\n",
    "This tutorial demonstrates the inference of YOLO-KP SDNN (training example scripts [here](https://github.com/lava-nc/lava-dl/tree/main/tutorials/lava/lib/dl/slayer/tiny_yolo_sdnn)) on both CPU and Loihi 2 neurocore.\n",
    "\n",
    "![image](https://github.com/lava-nc/lava/assets/29907126/61057e64-71b3-4ab8-a7ea-39d0cdbac70d)\n",
    "\n",
    "YOLO-KP is a fully convolutional single-headed variant of TinyYOLOv3 object detection architecture specifically designed for 8 chip Loihi 2 form factor called Kapoho Point (KP). The inference example uses the following lava components\n",
    "\n",
    "1. __Network on Loihi 2:__ YOLO-KP network generated from its NetX description. It is a hierarchical network consisting of all the layers of YOLO-KP. This is the portion that runs on Loihi.\n",
    "2. __Data sparsification on SuperHost:__ Delta encoder process that performs frame difference to sparsify the input being communicated to the YOLO-KP network. This process runs on Python.\n",
    "3. __Data communication in and out of lava processes:__ `Injector` process to send raw input to the lava network and `Extractor` process to receive raw output of YOLO-KP. These processes run on Python.\n",
    "4. __Data relay in and out of Loihi chip:__ Input and output adapter process which relay the communication into the chip and out of the chip. Since YOLO-KP is fully convolutional, the adapters translate to/from python spike and Loihi convolution spike.\n",
    "\n",
    "> ℹ️ This example currently does not make use of high speed IO capabilities of Loihi and hence the execution is slow. Once the software support is enabled in Lava, these adapters will not be required and shall be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56595d79-183f-4b78-a000-e8fbefcfd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg, Loihi2SimCfg\n",
    "from lava.proc import embedded_io as eio\n",
    "from lava.proc import io\n",
    "\n",
    "from lava.lib.dl import netx\n",
    "from lava.lib.dl import slayer\n",
    "from lava.lib.dl.slayer import obd\n",
    "\n",
    "from utils import DataGenerator, YOLOPredictor, nms, YOLOMonitor\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb22d4-d01b-4219-a106-d7ce40c750b3",
   "metadata": {},
   "source": [
    "# Import modules for Loihi2 execution\n",
    "\n",
    "Check if Loihi2 compiler is available and import related modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08beb08c-b9a2-44e1-ad63-d2fa9f2cfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.utils.system import Loihi2\n",
    "Loihi2.preferred_partition = 'loihi'\n",
    "loihi2_is_available = Loihi2.is_loihi2_available\n",
    "\n",
    "loihi2_is_available = False\n",
    "\n",
    "if loihi2_is_available:\n",
    "    print(f'Running on {Loihi2.partition}')\n",
    "    from lava.magma.compiler.subcompilers.nc.ncproc_compiler import CompilerOptions\n",
    "    CompilerOptions.verbose = True\n",
    "    compression = io.encoder.Compression.DELTA_SPARSE_8\n",
    "else:\n",
    "    print(\"Loihi2 compiler is not available in this system. \"\n",
    "          \"This tutorial will execute on CPU backend.\")\n",
    "    compression = io.encoder.Compression.DENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b3f8a-3405-496a-bae8-c5e3c4bac788",
   "metadata": {},
   "source": [
    "## Set execution parameters\n",
    "\n",
    "The network execution parameters can be divided into three categories:\n",
    "\n",
    "1. __Model parameters:__ these are parameters of the YOLO model used for the training and shall be reused to replicate the same behavior during inference.\n",
    "2. __Inference parametrs:__ these are parameters just for the inference.\n",
    "3. __Data processing parameters:__ these are parameters need to perform _pre_ and _post_ processing before the input and on the output of the network respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb59a7-04ae-4a5f-89a1-7b3fcb81750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model arguments\n",
    "trained_folder = os.path.abspath('../../slayer/tiny_yolo_sdnn/Trained_yolo_kp_events')\n",
    "with open(trained_folder + '/args.txt', 'rt') as f:\n",
    "    model_args = slayer.utils.dotdict(yaml.safe_load(f))\n",
    "\n",
    "# Additional inference arguments\n",
    "inference_args = slayer.utils.dotdict(loihi=loihi2_is_available,\n",
    "                                      spike_exp=4,    # This sets the decimal/fraction precision of spike message to 4 bits\n",
    "                                      num_steps=5)  # Number of frames to perform inference on\n",
    "\n",
    "# Pre and post processing parameters\n",
    "#pre_args = slayer.utils.dotdict(input_mean=np.array([0.485, 0.456, 0.406]),  # Input normalization mean\n",
    "#                                input_std=np.array([0.229, 0.224, 0.225]))   #                     & std\n",
    "post_args = slayer.utils.dotdict(anchors=np.array([(0.28, 0.22),  # YOLO head's anchor preset scales\n",
    "                                                   (0.38, 0.48),\n",
    "                                                   (0.90, 0.78)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9ad4b-6c01-4f85-9413-8761aa725f07",
   "metadata": {},
   "source": [
    "## Load YOLO-KP network\n",
    "\n",
    "Loading the network is a simple NetX call on the trained model computational graph. It will generate an hierarchical lava process representing the entire YOLO-KP network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21049ee5-398d-4c7a-8431-0f6322e747de",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = netx.hdf5.Network(trained_folder + '/network.net',\n",
    "                        input_shape = (448, 448, 2),\n",
    "                        #skip_layers = 1,  # First layer does delta encoding. We will only send it's sparsified output\n",
    "                        input_message_bits=16,  # This means the network takes 16bit graded spike input\n",
    "                        spike_exp=inference_args.spike_exp)\n",
    "print(f'The model was trained for {model_args.dataset} dataset')\n",
    "print(f'\\nNetwork Architecture ({model_args.model}):'); print('=' * (24 + len(model_args.model))); print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afeb7d-53ba-472f-9ef4-967d8043da14",
   "metadata": {},
   "source": [
    "## Dataset and input source\n",
    "\n",
    "The dataset is the same module that is used for training. It is wrapped around by a data generator module that will generate an individual frame and its annotation at every time-step. The data generator also takes care of data normalization using the mean and variance supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaacf43-0ce3-4e95-b331-59c6f609acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = obd.dataset.PropheseeAutomotive(root=model_args.path,\n",
    "                           train=False, randomize_seq=False,\n",
    "                           seq_len=inference_args.num_steps)\n",
    "data_gen = DataGenerator(dataset=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeace54f",
   "metadata": {},
   "source": [
    "## Input preprocessing and encoding\n",
    "\n",
    "The input preprocessing involves quantization of the numeric data making it ready to be processed on the chip. A fractional representation of 6 bits was used in the weight of the network during training (`weight_exp`) which is also accounted for during quantization.\n",
    "\n",
    "The quantized input frames are then processed the the lava processes `sender`, `encoder` (and `inp_adapter` for Loihi execution) which will be connected in a sequential manner below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize = netx.modules.Quantize(exp=6)  # convert to fixed point representation with 6 bit of fraction\n",
    "sender = io.injector.Injector(shape=net.inp.shape, buffer_size=128)\n",
    "#encoder = io.encoder.DeltaEncoder(shape=net.inp.shape,\n",
    "#                                  vth=net.net_config['layer'][0]['neuron']['vThMant'],\n",
    "#                                  spike_exp=0 if inference_args.loihi else net.spike_exp,\n",
    "#                                  num_bits=8,\n",
    "#                                  compression=compression)\n",
    "\n",
    "if inference_args.loihi:\n",
    "    # This is needed for the time being until high speed IO is enabled\n",
    "    inp_adapter = eio.spike.PyToN3ConvAdapter(shape=(448, 448, 2),\n",
    "                                              num_message_bits=16,\n",
    "                                              spike_exp=net.spike_exp,\n",
    "                                              compression=compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc614a5",
   "metadata": {},
   "source": [
    "## Output decoding and post processing\n",
    "\n",
    "The output of YOLO-KP goes through (`state_adapter` for Loihi execution), `receiver` and `dequantizer` lava processes which will be connected sequentially. The raw outputs needs to be processed using `yolo_predictor` which transforms the input to the actual bounding box predictions of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_args.loihi:\n",
    "    # This is needed for the time being until high speed IO is enabled\n",
    "    state_adapter = eio.state.ReadConv(shape=net.out.shape)\n",
    "receiver = io.extractor.Extractor(shape=net.out.shape, buffer_size=128)\n",
    "dequantize = netx.modules.Dequantize(exp=net.spike_exp + 12, num_raw_bits=24)\n",
    "yolo_predictor = YOLOPredictor(anchors=post_args.anchors, clamp_max=model_args.clamp_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3164b-8d41-402f-adac-e39264f88e47",
   "metadata": {},
   "source": [
    "## Output visualization\n",
    "\n",
    "`YOLOMonitor` is a flexible output visualization and evaluation module. It continuously evaluates the mAP score of the output predictions. It can also be passed a callable function that can be used to display. In this case it is a basic iPython display routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c9df9-971f-4eb3-aa45-633081fd9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_visualizer(annotated_frame, map_score, frame_idx):\n",
    "    clear_output(wait=True)\n",
    "    display(annotated_frame)\n",
    "    print(f'Processed frame {frame_idx}')\n",
    "    print(f'Object detection mAP@0.5 = {map_score:.2f}')\n",
    "    \n",
    "yolo_monitor = YOLOMonitor(viz_fx=output_visualizer, class_list=test_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba7ca7",
   "metadata": {},
   "source": [
    "## Data buffers / delays\n",
    "\n",
    "There is a latency in the prediction equal to the number of layers the network has and the encoding step. Two FIFO buffers are used to synchronize the input frame and target annotation with the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_buffer = netx.modules.FIFO(depth=len(net) + 1)\n",
    "annotation_buffer = netx.modules.FIFO(depth=len(net) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3b7d2",
   "metadata": {},
   "source": [
    "# Connect Lava processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2571441-fd3c-447c-8e5d-703e23d313d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inference_args.loihi:\n",
    "    sender.out_port.connect(inp_adapter.inp)\n",
    "    #encoder.s_out.connect(inp_adapter.inp)\n",
    "    inp_adapter.out.connect(net.inp)\n",
    "    state_adapter.connect_var(net.out_layer.neuron.sigma)\n",
    "    state_adapter.out.connect(receiver.in_port)\n",
    "else:\n",
    "    sender.out_port.connect(net.inp)\n",
    "    #encoder.s_out.connect(net.inp)\n",
    "    net.out.connect(receiver.in_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67623b71",
   "metadata": {},
   "source": [
    "# Setup execution\n",
    "\n",
    "The network is run in _non-blocking mode_. Note the `blocking=False` argument below. In non-blocking mode we can start running the lava process and do other computations in parallel. Here we will preprocess the data, send it to lava network using `sender` (`lava.proc.io.injector.Injector` instance), receive data from lava using `receiver` (`lava.proc.io.extractor.Extractor` instance), and perform additional processing, while the Lava network is running in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = inference_args.num_steps\n",
    "run_condition = RunSteps(num_steps=num_steps, blocking=False)\n",
    "\n",
    "if inference_args.loihi:\n",
    "    exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelSparse}\n",
    "    run_config = Loihi2HwCfg(exception_proc_model_map=exception_proc_model_map)\n",
    "else:\n",
    "    exception_proc_model_map = {io.encoder.DeltaEncoder: io.encoder.PyDeltaEncoderModelDense}\n",
    "    run_config = Loihi2SimCfg(select_tag='fixed_pt',\n",
    "                              exception_proc_model_map=exception_proc_model_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33bdc8",
   "metadata": {},
   "source": [
    "# Run YOLO-KP inference\n",
    "\n",
    "The following will compile and run the Lava network.\n",
    "\n",
    "> ℹ️ The network is large. It will take a while for the compilation to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender._log_config.level = logging.WARN\n",
    "sender.run(condition=run_condition, run_cfg=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2fbc3-c069-40be-9124-2e4db5d06f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(num_steps):\n",
    "    frame, annotation, raw_frame = data_gen()\n",
    "    #frame = quantize(frame)\n",
    "    \n",
    "    sender.send(frame)        # This sends the input frame to the Lava network\n",
    "    out = receiver.receive()  # This receives the output from the Lava network\n",
    "    \n",
    "    out = dequantize(out)\n",
    "    input_frame = frame_buffer(raw_frame)\n",
    "    gt_ann = annotation_buffer(annotation)\n",
    "    if input_frame is not None:  # valid output from FIFO buffer\n",
    "        predictions = yolo_predictor(out)\n",
    "        pred_bbox = nms(predictions)\n",
    "        gt_bbox = obd.bbox.utils.tensor_from_annotation(gt_ann).cpu().data.numpy()\n",
    "        yolo_monitor(input_frame, gt_bbox, pred_bbox)\n",
    "    else:\n",
    "        print(f'Frame {t} queued in pipeline.', end='\\r')\n",
    "\n",
    "sender.wait()\n",
    "sender.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
